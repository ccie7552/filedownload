import os
import time
import re
import requests
import fitz  # PyMuPDF (for PDF text extraction)
import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
from PyPDF2 import PdfReader, errors
from datetime import datetime
import xlsxwriter # xlsxwriter ì¶”ê°€

# --- ì„¤ì • ---
BASE_URL = "https://nedrug.mfds.go.kr/CCBAR01F012/getList"

# í˜„ì¬ Python ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì´ ìœ„ì¹˜í•œ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ë³¸ ì €ì¥ ë””ë ‰í† ë¦¬ë¡œ ì„¤ì •
SCRIPT_RUN_DIR = os.path.dirname(os.path.abspath(__file__))

# ê²°ê³¼ ë””ë ‰í† ë¦¬ ì´ë¦„ì„ 'nedrug_ë…„ë„_ì›”ì¼_ì‹œê°„_ë¶„' í˜•ì‹ìœ¼ë¡œ êµ¬ì„±
now = datetime.now()
RESULT_FOLDER_NAME = now.strftime("nedrug_%Y%m%d_%H%M")

# ìµœì¢… ê²°ê³¼ë¬¼ (ì—‘ì…€)ì´ ì €ì¥ë  ë””ë ‰í† ë¦¬
EXCEL_SAVE_DIR = os.path.join(SCRIPT_RUN_DIR, RESULT_FOLDER_NAME)

# PDF íŒŒì¼ì´ ì €ì¥ë  ë””ë ‰í† ë¦¬ (ì´ì œ PDFë§Œ ë‹¤ìš´ë¡œë“œí•˜ë¯€ë¡œ ì´ë¦„ ë³€ê²½ ë¶ˆí•„ìš”)
DOWNLOAD_DIR = os.path.join(EXCEL_SAVE_DIR, "nedrug_pdfs")

# í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(EXCEL_SAVE_DIR, exist_ok=True)
os.makedirs(DOWNLOAD_DIR, exist_ok=True)

print(f"ğŸ“ ì €ì¥ ê²½ë¡œ ì„¤ì •:")
print(f"   ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ í´ë”: {SCRIPT_RUN_DIR}")
print(f"   ê²°ê³¼ ì €ì¥ í´ë”: {EXCEL_SAVE_DIR}")
print(f"   PDF ì €ì¥ í´ë”: {DOWNLOAD_DIR}")

# --- í¬ë¡¬ ì„¤ì • ---
options = Options()
options.add_argument("--headless")
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
options.add_argument("--disable-gpu")
options.add_argument("--window-size=1920,1080")

# --- User-Agent ë° ì¬ì‹œë„ ì„¤ì • ---
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}
MAX_RETRIES = 3
RETRY_DELAY = 2 # ì´ˆ

# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜ (ì¤‘ë³µ ì œê±° ë° ê°€ë…ì„± í–¥ìƒ) ---

def _extract_text_from_pdf_with_fitz(pdf_path):
    """PyMuPDF(fitz)ë¥¼ ì‚¬ìš©í•˜ì—¬ PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        doc = fitz.open(pdf_path)
        full_text = "\n".join(page.get_text() for page in doc)
        doc.close()
        return full_text if full_text.strip() else ""
    except Exception as e:
        print(f"        âš ï¸  PyMuPDFë¡œ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return ""

def _extract_text_from_pdf_with_pypdf2(pdf_path):
    """PyPDF2ë¥¼ ì‚¬ìš©í•˜ì—¬ PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        reader = PdfReader(pdf_path)
        full_text = "\n".join(page.extract_text() for page in reader.pages)
        return full_text if full_text.strip() else ""
    except (errors.PdfReadError, Exception) as e: # PDF Read Error ë° ê¸°íƒ€ ì˜ˆì™¸ ì²˜ë¦¬
        print(f"        âš ï¸  PyPDF2ë¡œ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return ""

def _extract_date_with_patterns(text, patterns, source_name=""):
    """ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ íŒ¨í„´ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‚ ì§œ ì¶”ì¶œ"""
    for i, pattern in enumerate(patterns, 1):
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            groups = match.groups()
            if len(groups) >= 3:
                y, m, d = groups[:3]
                try:
                    formatted_date = f"{int(y):04d}-{int(m):02d}-{int(d):02d}"
                    return formatted_date, match.group(), f"(íŒ¨í„´ {i})"
                except ValueError:
                    # print(f"        âš ï¸  {source_name} íŒ¨í„´ {i} ì¼ì¹˜í–ˆìœ¼ë‚˜ ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨: {groups}")
                    continue
    return "", "", ""


# --- ê¸°ì¡´ í•¨ìˆ˜ë“¤ (ì¼ë¶€ ìˆ˜ì •) ---

def get_total_pages(driver):
    """ì´ í˜ì´ì§€ ìˆ˜ë¥¼ í™•ì¸í•˜ëŠ” í•¨ìˆ˜"""
    try:
        last_page_btn = WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.CSS_SELECTOR, "button[title*='ë§ˆì§€ë§‰']"))
        )
        last_page_btn.click()
        time.sleep(2)
       
        current_url = driver.current_url
        total_pages = 1
        total_items = 0
       
        if "totalPages=" in current_url:
            total_pages = int(re.search(r'totalPages=(\d+)', current_url).group(1))
            print(f"âœ… ì´ í˜ì´ì§€ ìˆ˜: {total_pages}")
           
            rows = driver.find_elements(By.CSS_SELECTOR, "table tbody tr")
            last_page_items = len(rows)
            total_items = (total_pages - 1) * 10 + last_page_items
            print(f"âœ… ì´ í•­ëª© ìˆ˜: {total_items}ê±´")
           
        else:
            page_links = driver.find_elements(By.CSS_SELECTOR, "div.pagination a")
            if page_links:
                total_pages = int(page_links[-1].text.strip())
                total_items = total_pages * 10
                print(f"âœ… ì´ í˜ì´ì§€ ìˆ˜: {total_pages} (ì¶”ì • í•­ëª© ìˆ˜: {total_items}ê±´)")
       
        return total_pages, total_items
       
    except Exception as e:
        print(f"âš ï¸  ì´ í˜ì´ì§€ ìˆ˜ í™•ì¸ ì‹¤íŒ¨: {e}")
        return 1, 10

def navigate_to_page(driver, page_num):
    """íŠ¹ì • í˜ì´ì§€ë¡œ ì´ë™í•˜ëŠ” í•¨ìˆ˜"""
    try:
        page_url = f"{BASE_URL}?page={page_num}&limit=10"
        driver.get(page_url)
       
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "table tbody tr"))
        )
        time.sleep(1)
        return True
    except TimeoutException:
        print(f"âš ï¸  í˜ì´ì§€ {page_num} ë¡œë”© ì‹¤íŒ¨")
        return False

def extract_ingredient_name_from_html(driver):
    """HTML í˜ì´ì§€ì—ì„œ ì„±ë¶„ì •ë³´ í…Œì´ë¸”ì˜ ì›ë£Œ/ì„±ë¶„ëª…(ì˜ë¬¸) ì¶”ì¶œ"""
    try:
        ingredient_table = driver.find_elements(By.XPATH, "//p[contains(@class, 'cont_title3') and contains(text(), 'ì„±ë¶„ì •ë³´')]/following-sibling::div//table")
        if not ingredient_table:
            return ""
        try:
            english_name_cell = ingredient_table[0].find_element(By.XPATH, ".//tbody/tr[1]/td[3]")
            ingredient_name = english_name_cell.text.strip()
            return ingredient_name if ingredient_name else ""
        except Exception:
            return ""
    except Exception:
        return ""

def extract_submit_deadline_from_html(driver):
    """HTML í˜ì´ì§€ì—ì„œ ì˜ê²¬ì œì¶œê¸°í•œ ì¶”ì¶œ"""
    try:
        deadline_cell = driver.find_elements(By.XPATH, "//th[contains(text(), 'ì˜ê²¬ì œì¶œê¸°í•œ')]/following-sibling::td")
        if deadline_cell:
            deadline_text = deadline_cell[0].text.strip()
            return deadline_text if re.match(r'\d{4}-\d{2}-\d{2}', deadline_text) else ""
        else:
            return ""
    except Exception:
        return ""

def extract_plan_date_from_html(driver):
    """HTML í˜ì´ì§€ì—ì„œ í—ˆê°€ì‚¬í•­ ë³€ê²½ëª…ë ¹ ì˜ˆì •ì¼ ì¶”ì¶œ"""
    try:
        content_textarea = driver.find_elements(By.XPATH, "//th[contains(text(), 'ë‚´ìš©')]/following-sibling::td//textarea")
        if content_textarea:
            content_text = content_textarea[0].text.strip()
            plan_patterns = [
                r"í—ˆê°€ì‚¬í•­\s*ë³€ê²½\s*ëª…ë ¹\s*ì˜ˆì •ì¼\s*[:ï¼š]\s*(\d{4})\.(\d{1,2})\.(\d{1,2})",
                r"ë³€ê²½\s*ëª…ë ¹\s*ì˜ˆì •ì¼\s*[:ï¼š]\s*(\d{4})\.(\d{1,2})\.(\d{1,2})",
                r"ì˜ˆì •ì¼\s*[:ï¼š]\s*(\d{4})\.(\d{1,2})\.(\d{1,2})",
                r"â—‹\s*í—ˆê°€ì‚¬í•­\s*ë³€ê²½\s*ëª…ë ¹\s*ì˜ˆì •ì¼\s*[:ï¼š]\s*(\d{4})\.(\d{1,2})\.(\d{1,2})",
            ]
            for pattern in plan_patterns:
                plan_match = re.search(pattern, content_text, re.IGNORECASE)
                if plan_match:
                    y, m, d = plan_match.groups()
                    return f"{y}-{int(m):02d}-{int(d):02d}"
            return ""
        else:
            return ""
    except Exception:
        return ""

def extract_reflect_date_from_html(driver):
    """HTML í˜ì´ì§€ì—ì„œ í—ˆê°€ë°˜ì˜ì¼ì ì¶”ì¶œ"""
    try:
        reflect_cell = driver.find_elements(By.XPATH, "//th[contains(text(), 'í—ˆê°€ë°˜ì˜ì¼ì')]/following-sibling::td")
        if reflect_cell:
            reflect_text = reflect_cell[0].text.strip()
            return reflect_text if re.match(r'\d{4}-\d{2}-\d{2}', reflect_text) else ""
        else:
            return ""
    except Exception:
        return ""

def extract_ingredient_name_from_pdf(full_text):
    """PDFì—ì„œ ì›ë£Œ/ì„±ë¶„ëª…(ì˜ë¬¸) ì¶”ì¶œ í•¨ìˆ˜ (HTML ì¶”ì¶œ ì‹¤íŒ¨ì‹œ ë°±ì—…ìš©)"""
    try:
        patterns = [
            r"ì•Œë¦¼\(([A-Za-z\s]+)\s*ì„±ë¶„\s*ì œì œ\)",
            r"ì˜ˆê³ \s*ì•Œë¦¼\(([A-Za-z\s]+)\s*ì„±ë¶„\s*ì œì œ\)",
            r"ì˜ê²¬ì¡°íšŒ\(([A-Za-z\s]+)\s*ì„±ë¶„\s*ì œì œ\)",
            r"ì œëª©[^)]*\(([A-Za-z\s]+)\s*ì„±ë¶„\s*ì œì œ\)",
            r"'([A-Za-z][A-Za-z\s]*[A-Za-z])'\s*ì„±ë¶„",
            r"([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)",
        ]
        for i, pattern in enumerate(patterns, 1):
            match = re.search(pattern, full_text, re.IGNORECASE)
            if match:
                ingredient = match.group(1).strip()
                ingredient = re.sub(r'\s+', ' ', ingredient)
                if len(ingredient) > 2 and any(c.isalpha() for c in ingredient):
                    print(f"    âœ… PDFì—ì„œ ì›ë£Œ/ì„±ë¶„ëª… ì¶”ì¶œ ì„±ê³µ (íŒ¨í„´ {i}): {ingredient}")
                    return ingredient
        return ""
    except Exception as e:
        print(f"    âš ï¸  PDFì—ì„œ ì›ë£Œ/ì„±ë¶„ëª… ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return ""

def extract_exec_date_from_pdf(pdf_path):
    """
    PDFì—ì„œ 'ì‹œí–‰' ë‚ ì§œë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜.
    PyMuPDF (fitz)ì™€ PyPDF2ë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ì—¬ ì¶”ì¶œ ì„±ê³µë¥ ì„ ë†’ì…ë‹ˆë‹¤.
    """
    exec_date = ""
    full_text_fitz = ""

    print(f"        ğŸ” extract_exec_date_from_pdf í˜¸ì¶œ: {os.path.basename(pdf_path)}")
    
    # 1. PyMuPDF (fitz)ë¥¼ ì´ìš©í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
    full_text_fitz = _extract_text_from_pdf_with_fitz(pdf_path)
    if full_text_fitz:
        print(f"        âœ… PyMuPDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ. ê¸¸ì´: {len(full_text_fitz)}")
    else:
        print(f"        âš ï¸  PyMuPDF í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŒ - PyPDF2 ì‹œë„")

    # 2. PyMuPDFë¡œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œ íŒ¨í„´ ê²€ìƒ‰
    if full_text_fitz:
        search_text = full_text_fitz
        print(f"        ğŸ” PyMuPDF í…ìŠ¤íŠ¸ ì „ì²´ ê²€ìƒ‰ ì‹œì‘ (ê¸¸ì´: {len(search_text)})")

        exec_patterns = [
            r"ì‹œí–‰\s*\((\d{4})\.\s*(\d{1,2})\.\s*(\d{1,2})\.\)",
            r"ì‹œí–‰\s+[^)]*\s*\((\d{4})\.\s*(\d{1,2})\.\s*(\d{1,2})\.\)",
            r"(\d{4})\.\s*(\d{1,2})\.\s*(\d{1,2})\.\)\s*ì‹œí–‰",
            r"ì‹œí–‰ì¼\s*[:ï¼š]?\s*(\d{4})\s*ë…„\s*(\d{1,2})\s*ì›”\s*(\d{1,2})\s*ì¼",
            r"ì‹œí–‰\s*[:ï¼š]?\s*(\d{4})\s*ë…„\s*(\d{1,2})\s*ì›”\s*(\d{1,2})\s*ì¼",
            r"(\d{4})\s*ë…„\s*(\d{1,2})\s*ì›”\s*(\d{1,2})\s*ì¼\s*ì‹œí–‰",
            r"ì‹œí–‰\s*[:ï¼š]?\s*(\d{4})[.\-]\s*(\d{1,2})[.\-]\s*(\d{1,2})",
            r"(\d{4})[.\-]\s*(\d{1,2})[.\-]\s*(\d{1,2})\s*ì‹œí–‰",
            r"ì‹œí–‰\s*[^0-9]*(\d{4})\.(\d{1,2})\.(\d{1,2})\.",
            r"ì‹œí–‰ì¼ì\s*(\d{4})-(\d{1,2})-(\d{1,2})",
            r"ì‹œí–‰[^:]*:\s*(\d{4})\s*ë…„\s*(\d{1,2})\s*ì›”\s*(\d{1,2})\s*ì¼",
            r"(\d{4})\s*.\s*(\d{1,2})\s*.\s*(\d{1,2})\s*.\s*\(ì‹œí–‰\)",
            r"\((\d{4})\s*.\s*(\d{1,2})\s*.\s*(\d{1,2})\s*.\)\s*ì‹œí–‰",
        ]
        
        exec_date, matched_text, pattern_info = _extract_date_with_patterns(search_text, exec_patterns, "PyMuPDF í…ìŠ¤íŠ¸")
        if exec_date:
            print(f"        âœ… PyMuPDF í…ìŠ¤íŠ¸ì—ì„œ ì‹œí–‰ë‚ ì§œ ì¶”ì¶œ ì„±ê³µ {pattern_info}: {exec_date} (ë§¤ì¹˜: '{matched_text}')")
            return exec_date
        else:
            print(f"        âŒ PyMuPDF í…ìŠ¤íŠ¸ì—ì„œ ì‹œí–‰ë‚ ì§œ íŒ¨í„´ì„ ì°¾ì§€ ëª»í•¨. í…ìŠ¤íŠ¸ ìƒ˜í”Œ (ë§ˆì§€ë§‰ 500ì):\n{search_text[-500:]}...")
            for match_obj in re.finditer(r"ì‹œí–‰.{0,100}(?:\d{4}[ë…„.\-]\d{1,2}[ì›”.\-]\d{1,2}[ì¼.]?)", search_text, re.IGNORECASE):
                print(f"            ğŸ‘‰ 'ì‹œí–‰' ì£¼ë³€ì—ì„œ ë‚ ì§œì™€ í•¨ê»˜ ë°œê²¬ëœ í…ìŠ¤íŠ¸: {match_obj.group()}")

    # 3. PyMuPDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆê±°ë‚˜, íŒ¨í„´ì„ ì°¾ì§€ ëª»í–ˆë‹¤ë©´ PyPDF2 ì‹œë„
    if not exec_date:
        print(f"        ğŸ” PyPDF2ë¡œ ì‹œí–‰ë‚ ì§œ ì¶”ì¶œ ì‹œë„...")
        text_pypdf2 = _extract_text_from_pdf_with_pypdf2(pdf_path)
        if text_pypdf2:
            print(f"        âœ… PyPDF2 í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ. ê¸¸ì´: {len(text_pypdf2)}")
            # PyPDF2 ì „ìš© íŒ¨í„´ (ê´„í˜¸ ì•ˆì˜ ë‚ ì§œê°€ ì˜ ì¡í˜)
            date_pattern_pypdf2_specific = r"\((20\d{2})\.\s*(\d{1,2})\.\s*(\d{1,2})\.\)"
            
            # 'ì‹œí–‰'ì´ ìˆëŠ” ì¤„ì—ì„œ PyMuPDFì˜ ëª¨ë“  íŒ¨í„´ + PyPDF2 ì „ìš© íŒ¨í„´ ì‹œë„
            all_pypdf2_patterns = exec_patterns + [date_pattern_pypdf2_specific]
            
            # PyPDF2ëŠ” ì¤„ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ëŠ” ê²ƒì´ íš¨ìœ¨ì ì´ë¯€ë¡œ, ì¤„ë³„ ê²€ìƒ‰ ìœ ì§€
            for line in text_pypdf2.splitlines():
                if "ì‹œí–‰" in line:
                    print(f"            ğŸ” PyPDF2 'ì‹œí–‰' ë°œê²¬ ì¤„: '{line.strip()}'")
                    exec_date, matched_text, pattern_info = _extract_date_with_patterns(line, all_pypdf2_patterns, "PyPDF2 ì¤„ í…ìŠ¤íŠ¸")
                    if exec_date:
                        print(f"            âœ… PyPDF2ë¡œ ì‹œí–‰ë‚ ì§œ ì¶”ì¶œ ì„±ê³µ {pattern_info}: {exec_date} (ë§¤ì¹˜: '{matched_text}')")
                        return exec_date
                    else:
                        print(f"            âŒ PyPDF2: 'ì‹œí–‰'ì´ ìˆëŠ” ì¤„ì—ì„œ ë‚ ì§œ íŒ¨í„´ì„ ì°¾ì§€ ëª»í•¨ (ì¤„: '{line.strip()}')")
            print(f"        âŒ PyPDF2ì—ì„œë„ ì‹œí–‰ ë‚ ì§œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ëª¨ë“  í˜ì´ì§€ ê²€ìƒ‰ ì™„ë£Œ)")
        else:
            print(f"        âš ï¸  PyPDF2 í…ìŠ¤íŠ¸ë„ ë¹„ì–´ìˆìŒ.")

    return exec_date


def extract_submit_deadline_from_pdf(full_text):
    """PDF í…ìŠ¤íŠ¸ì—ì„œ ì˜ê²¬ì œì¶œê¸°í•œ ì¶”ì¶œ"""
    patterns = [
        r"ì˜ê²¬ì œì¶œê¸°í•œ\s*[:ï¼š]?\s*(\d{4})[.\-ë…„\s]*(\d{1,2})[.\-ì›”\s]*(\d{1,2})[ì¼\s]*",
        r"ê¸°í•œ\s*:\s*(\d{4})[.\- ]*(\d{1,2})[.\- ]*(\d{1,2})",
        r"ì˜ê²¬ìˆ˜ë ´ê¸°ê°„\s*:\s*(\d{4})[.\- ]*(\d{1,2})[.\- ]*(\d{1,2})\s*~",
        r"(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼ê¹Œì§€",
        r"(\d{4})\.(\d{1,2})\.(\d{1,2})\s*ê¹Œì§€"
    ]
    for i, pattern in enumerate(patterns, 1):
        match = re.search(pattern, full_text, re.IGNORECASE)
        if match:
            y, m, d = match.groups()[:3]
            formatted_date = f"{y}-{int(m):02d}-{int(d):02d}"
            return formatted_date
    return ""

def extract_plan_date_from_pdf(full_text):
    """PDF í…ìŠ¤íŠ¸ì—ì„œ í—ˆê°€ì‚¬í•­ ë³€ê²½ëª…ë ¹ ì˜ˆì •ì¼ ì¶”ì¶œ"""
    patterns = [
        r"í—ˆê°€ì‚¬í•­\s*ë³€ê²½\s*ëª…ë ¹\s*ì˜ˆì •ì¼\s*[:ï¼š]?\s*(\d{4})[.\-ë…„\s]*(\d{1,2})[.\-ì›”\s]*(\d{1,2})[ì¼\s]*",
        r"ë³€ê²½\s*ëª…ë ¹\s*ì˜ˆì •ì¼\s*[:ï¼š]?\s*(\d{4})[.\-ë…„\s]*(\d{1,2})[.\-ì›”\s]*(\d{1,2})[ì¼\s]*",
        r"ì˜ˆì •ì¼\s*[:ï¼š]?\s*(\d{4})[.\-ë…„\s]*(\d{1,2})[.\-ì›”\s]*(\d{1,2})[ì¼\s]*",
        r"(\d{4})\s*ë…„\s*(\d{1,2})\s*ì›”\s*(\d{1,2})\s*ì¼\s*ë¶€í„°\s*ì‹œí–‰\s*ì˜ˆì •",
        r"(\d{4})\.(\d{1,2})\.(\d{1,2})\s*ì‹œí–‰\s*ì˜ˆì •"
    ]
    for i, pattern in enumerate(patterns, 1):
        match = re.search(pattern, full_text, re.IGNORECASE)
        if match:
            y, m, d = match.groups()[:3]
            formatted_date = f"{y}-{int(m):02d}-{int(d):02d}"
            return formatted_date
    return ""

def extract_reflect_date_from_pdf(full_text):
    """PDF í…ìŠ¤íŠ¸ì—ì„œ í—ˆê°€ë°˜ì˜ì¼ì ì¶”ì¶œ"""
    patterns = [
        r"í—ˆê°€ë°˜ì˜ì¼ì\s*[:ï¼š]?\s*(\d{4})[.\-ë…„\s]*(\d{1,2})[.\-ì›”\s]*(\d{1,2})[ì¼\s]*",
        r"ë°˜ì˜ì¼ì\s*[:ï¼š]?\s*(\d{4})[.\-ë…„\s]*(\d{1,2})[.\-ì›”\s]*(\d{1,2})[ì¼\s]*",
        r"ë³€ê²½\s*ë°˜ì˜ì¼ì\s*:\s*(\d{4})\s*(\d{1,2})\s*(\d{1,2})",
        r"(\d{4})\s*ë…„\s*(\d{1,2})\s*ì›”\s*(\d{1,2})\s*ì¼\s*ë³€ê²½\s*ë°˜ì˜",
        r"(\d{4})\.(\d{1,2})\.(\d{1,2})\s*ì¼\s*ë³€ê²½\s*ë°˜ì˜"
    ]
    for i, pattern in enumerate(patterns, 1):
        match = re.search(pattern, full_text, re.IGNORECASE)
        if match:
            y, m, d = match.groups()[:3]
            formatted_date = f"{y}-{int(m):02d}-{int(d):02d}"
            return formatted_date
    return ""

def process_single_item(driver, row, idx, downloaded_files, records):
    """ê°œë³„ í•­ëª©ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    current_item_processed_pdf_path = "" # í˜„ì¬ í•­ëª©ì—ì„œ ì¶”ì¶œì— ì„±ê³µí•œ PDFì˜ ê²½ë¡œ (í•˜ë‚˜ë§Œ í•„ìš”)
    
    try:
        cells = row.find_elements(By.TAG_NAME, "td")
        if len(cells) < 6:
            return
           
        status = cells[5].text.strip()
        title_elem = cells[1].find_element(By.TAG_NAME, "a")
        title = title_elem.text.strip()
        href = title_elem.get_attribute("href")
        change_reflect_date = cells[4].text.strip() if len(cells) > 4 else ""

        print(f"[{idx}] ì²˜ë¦¬ ì¤‘: {title} - {status}")

        if status not in ["ë³€ê²½ëª…ë ¹(ì•ˆ) ì˜ê²¬ì¡°íšŒ", "ì‚¬ì „ì˜ˆê³ ", "ë³€ê²½ëª…ë ¹"]:
            print(f"    â­ï¸  ìŠ¤í‚µ (ìƒíƒœ: {status})")
            return

        # ê´€ë ¨ URL ì €ì¥
        record_url = href

        driver.execute_script("window.open(arguments[0]);", href)
        driver.switch_to.window(driver.window_handles[-1])

        try:
            ingredient_name = extract_ingredient_name_from_html(driver)
            submit_deadline_from_html = ""
            plan_date_from_html = ""
            reflect_date_from_html = ""
           
            if status == "ë³€ê²½ëª…ë ¹(ì•ˆ) ì˜ê²¬ì¡°íšŒ":
                submit_deadline_from_html = extract_submit_deadline_from_html(driver)
            elif status == "ì‚¬ì „ì˜ˆê³ ":
                plan_date_from_html = extract_plan_date_from_html(driver)
            elif status == "ë³€ê²½ëª…ë ¹":
                reflect_date_from_html = extract_reflect_date_from_html(driver)
           
            need_pdf_processing = False
            # HTMLì—ì„œ ì •ë³´ë¥¼ ì¶©ë¶„íˆ ì–»ì§€ ëª»í–ˆê±°ë‚˜ ì‹œí–‰ë‚ ì§œ ì¶”ì¶œì´ í•„ìš”í•œ ê²½ìš° PDF ì²˜ë¦¬ ì‹œë„
            if not ingredient_name or \
               (status == "ë³€ê²½ëª…ë ¹(ì•ˆ) ì˜ê²¬ì¡°íšŒ" and not submit_deadline_from_html) or \
               (status == "ì‚¬ì „ì˜ˆê³ " and not plan_date_from_html) or \
               (status == "ë³€ê²½ëª…ë ¹" and not reflect_date_from_html) or \
               status in ["ë³€ê²½ëª…ë ¹(ì•ˆ) ì˜ê²¬ì¡°íšŒ", "ë³€ê²½ëª…ë ¹"]: # ì‹œí–‰ë‚ ì§œëŠ” PDFì—ì„œë§Œ ì¶”ì¶œ
                need_pdf_processing = True
           
            if not need_pdf_processing:
                print(f"    ğŸš€ HTMLì—ì„œ ëª¨ë“  ì •ë³´ ì¶”ì¶œ ì™„ë£Œ, PDF ë‹¤ìš´ë¡œë“œ ë° ì²˜ë¦¬ ìƒëµ")
            else:
                try:
                    WebDriverWait(driver, 10).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, "button[onclick^='downEdmsFile']"))
                    )
                    buttons = driver.find_elements(By.CSS_SELECTOR, "button[onclick^='downEdmsFile']")
                except TimeoutException:
                    print(f"    âš ï¸  ì²¨ë¶€íŒŒì¼ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ. PDF ì²˜ë¦¬ ë¶ˆê°€.")
                    buttons = []

                for btn in buttons:
                    file_id = ""
                    filename = ""
                    
                    try:
                        onclick = btn.get_attribute("onclick")
                        if not onclick:
                            continue
                           
                        file_id_match = re.search(r"downEdmsFile\('([^']+)',\s*'([^']+)'\)", onclick)
                        if not file_id_match:
                            file_id_match = re.search(r"downEdmsFile\('([^']+)'\)", onclick)
                            if file_id_match:
                                file_id = file_id_match.group(1)
                                filename = btn.get_attribute("title")
                                if not filename:
                                    filename = f"file_{file_id}.pdf" # í™•ì¥ìê°€ ì—†ìœ¼ë©´ ì¼ë‹¨ PDFë¡œ ê°€ì •
                            else:
                                continue
                        else:
                            file_id = file_id_match.group(1)
                            filename = file_id_match.group(2)

                        filename = filename.strip()
                        file_extension = os.path.splitext(filename)[1].lower()

                        # --- ìµœì í™” 1: PDF íŒŒì¼ë§Œ ë‹¤ìš´ë¡œë“œ ---
                        if file_extension != '.pdf':
                            print(f"    â­ï¸  PDF íŒŒì¼ ì•„ë‹˜ ({file_extension}), ë‹¤ìš´ë¡œë“œ ìŠ¤í‚µ: {filename}")
                            continue

                        if filename in downloaded_files:
                            print(f"    â­ï¸  ì´ë¯¸ ë‹¤ìš´ë¡œë“œë¨: {filename}")
                            continue

                        download_url = f"https://nedrug.mfds.go.kr/cmn/edms/down/{file_id}"
                        safe_filename = re.sub(r'[\\/*?:"<>|]', "_", filename)
                        # ê³µë°±ì„ ë°‘ì¤„ë¡œ ëŒ€ì²´
                        safe_filename = safe_filename.replace(" ", "_")
                        local_file_path = os.path.join(DOWNLOAD_DIR, safe_filename)

                        file_content = None
                        for attempt in range(MAX_RETRIES):
                            try:
                                print(f"    â³ {filename} ë‹¤ìš´ë¡œë“œ ì‹œë„ {attempt + 1}/{MAX_RETRIES}...")
                                response = requests.get(download_url, headers=HEADERS, timeout=30)
                                response.raise_for_status()
                                file_content = response.content
                                print(f"      âœ… ë‹¤ìš´ë¡œë“œ ì„±ê³µ. í¬ê¸°: {len(file_content)} bytes.")
                                break
                            except requests.exceptions.RequestException as req_err:
                                print(f"      âš ï¸  ë‹¤ìš´ë¡œë“œ ìš”ì²­ ì‹¤íŒ¨ (ì¬ì‹œë„ {attempt + 1}): {req_err}")
                                time.sleep(RETRY_DELAY)
                            except Exception as general_err:
                                print(f"      âš ï¸  ë‹¤ìš´ë¡œë“œ ì¤‘ ì¼ë°˜ ì˜¤ë¥˜ (ì¬ì‹œë„ {attempt + 1}): {general_err}")
                                time.sleep(RETRY_DELAY)
                        
                        if file_content is None:
                            print(f"   âŒ {filename} ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨. ë‹¤ìš´ë¡œë“œ ê±´ë„ˆëœœ.")
                            continue

                        try:
                            with open(local_file_path, "wb") as f:
                                f.write(file_content)
                            print(f"   ğŸ’¾ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {safe_filename}")
                            downloaded_files.add(filename) # ì„±ê³µì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ë§Œ setì— ì¶”ê°€
                            current_item_processed_pdf_path = local_file_path # ì´ í•­ëª©ì—ì„œ ì²˜ë¦¬í•  PDF ê²½ë¡œ ì €ì¥ (ì²« ë²ˆì§¸ ì„±ê³µí•œ PDF)
                            break # ì²« ë²ˆì§¸ PDFë§Œ ë‹¤ìš´ë¡œë“œ ì„±ê³µí•˜ë©´ ë‹¤ìŒ PDFëŠ” ìŠ¤í‚µ (ìµœì í™”)
                            
                        except Exception as save_err:
                            print(f"   âŒ {filename} ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {save_err}")
                            continue

                    except Exception as btn_proc_error:
                        print(f"    âš ï¸  ë²„íŠ¼({filename}) ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {btn_proc_error}")
                        continue
            
            # --- ë‹¤ìš´ë¡œë“œëœ PDF íŒŒì¼ (í˜¹ì€ HTMLì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸)ì—ì„œ ì •ë³´ ì¶”ì¶œ ---
            # í•œ ë²ˆ ì°¾ì€ ì‹œí–‰ë‚ ì§œ, ì œì¶œë‚ ì§œ, ì˜ˆì •ì¼, ë°˜ì˜ì¼ìëŠ” ë®ì–´ì“°ì§€ ì•Šë„ë¡ í”Œë˜ê·¸ ì‚¬ìš©
            record_exec_date = ""
            final_submit_deadline = ""
            final_plan_date = ""
            final_reflect_date = ""
            full_text_from_pdf = "" # í…ìŠ¤íŠ¸ ì¶”ì¶œì€ ì—¬ê¸°ì„œ í•œë²ˆë§Œ ìˆ˜í–‰
            record_pdf_path = "" # ê´€ë ¨ PDF ê²½ë¡œ ì €ì¥

            # PDFê°€ ì„±ê³µì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë˜ê³  ì €ì¥ë˜ì—ˆë‹¤ë©´ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
            if current_item_processed_pdf_path:
                print(f"    ğŸ” PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œì‘: {os.path.basename(current_item_processed_pdf_path)}")
                full_text_from_pdf = _extract_text_from_pdf_with_fitz(current_item_processed_pdf_path)
                if not full_text_from_pdf: # fitz ì‹¤íŒ¨ ì‹œ PyPDF2 ì‹œë„
                    full_text_from_pdf = _extract_text_from_pdf_with_pypdf2(current_item_processed_pdf_path)
                    if not full_text_from_pdf:
                        print(f"    âŒ {os.path.basename(current_item_processed_pdf_path)}ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ìµœì¢… ì‹¤íŒ¨.")
                # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´, ë‹¤ìš´ë¡œë“œëœ PDF ê²½ë¡œë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
                record_pdf_path = current_item_processed_pdf_path
            
            # HTMLì—ì„œ ì„±ë¶„ëª… ì¶”ì¶œì´ ì‹¤íŒ¨í–ˆë‹¤ë©´ PDF í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ ì‹œë„
            if not ingredient_name and full_text_from_pdf:
                ingredient_name = extract_ingredient_name_from_pdf(full_text_from_pdf)
                if ingredient_name:
                    print(f"    âœ… ìµœì¢… ì›ë£Œ/ì„±ë¶„ëª… (PDFì—ì„œ ì¶”ì¶œ): {ingredient_name}")

            # ì‹œí–‰ë‚ ì§œ ì¶”ì¶œ (ì•„ì§ ì°¾ì§€ ëª»í–ˆì„ ê²½ìš°ì—ë§Œ ì‹œë„)
            if status in ["ë³€ê²½ëª…ë ¹(ì•ˆ) ì˜ê²¬ì¡°íšŒ", "ë³€ê²½ëª…ë ¹"] and not record_exec_date and full_text_from_pdf:
                exec_date_found = extract_exec_date_from_pdf(current_item_processed_pdf_path) # í•¨ìˆ˜ ì¸ì ë³€ê²½ (í…ìŠ¤íŠ¸ ì¶”ì¶œì€ extract_exec_date_from_pdf ë‚´ë¶€ì—ì„œ ìˆ˜í–‰)
                if exec_date_found:
                    record_exec_date = exec_date_found
                    print(f"    âœ… ì‹œí–‰ë‚ ì§œ ì¶”ì¶œ ì„±ê³µ: {record_exec_date}")
                else:
                    print(f"    âŒ {os.path.basename(current_item_processed_pdf_path)} PDFì—ì„œ ì‹œí–‰ë‚ ì§œ ì°¾ê¸° ì‹¤íŒ¨.")
            
            # ì œì¶œë‚ ì§œ/ì˜ˆì •ì¼/ë°˜ì˜ì¼ì ì¶”ì¶œ (ì•„ì§ ì°¾ì§€ ëª»í–ˆê³ , í…ìŠ¤íŠ¸ê°€ ìˆë‹¤ë©´)
            if status == "ë³€ê²½ëª…ë ¹(ì•ˆ) ì˜ê²¬ì¡°íšŒ" and not submit_deadline_from_html and not final_submit_deadline and full_text_from_pdf:
                extracted_date = extract_submit_deadline_from_pdf(full_text_from_pdf)
                if extracted_date:
                    final_submit_deadline = extracted_date
                    print(f"    âœ… ì œì¶œë‚ ì§œ (PDFì—ì„œ ì¶”ì¶œ): {final_submit_deadline}")

            if status == "ì‚¬ì „ì˜ˆê³ " and not plan_date_from_html and not final_plan_date and full_text_from_pdf:
                extracted_date = extract_plan_date_from_pdf(full_text_from_pdf)
                if extracted_date:
                    final_plan_date = extracted_date
                    print(f"    âœ… ì˜ˆì •ì¼ (PDFì—ì„œ ì¶”ì¶œ): {final_plan_date}")

            if status == "ë³€ê²½ëª…ë ¹" and not reflect_date_from_html and not final_reflect_date and full_text_from_pdf:
                extracted_date = extract_reflect_date_from_pdf(full_text_from_pdf)
                if extracted_date:
                    final_reflect_date = extracted_date
                    print(f"    âœ… ë°˜ì˜ì¼ì (PDFì—ì„œ ì¶”ì¶œ): {final_reflect_date}")

            # ìµœì¢… ì„±ë¶„ëª… í™•ì¸ (HTML ë˜ëŠ” PDFì—ì„œ ì¶”ì¶œëœ ê²ƒ ì¤‘ ë§ˆì§€ë§‰ìœ¼ë¡œ ì—…ë°ì´íŠ¸ëœ ê°’)
            if not ingredient_name:
                print(f"    âŒ ì›ë£Œ/ì„±ë¶„ëª… ì¶”ì¶œ ì‹¤íŒ¨ (HTML ë° ëª¨ë“  PDF)")
                ingredient_name = ""

            final_exec_date = record_exec_date if record_exec_date else ""

            # ë‹¨ê³„ë³„ë¡œ ë‹¤ë¥¸ ë ˆì½”ë“œ êµ¬ì¡° ìƒì„±
            if status == "ë³€ê²½ëª…ë ¹(ì•ˆ) ì˜ê²¬ì¡°íšŒ":
                record = {
                    "A_ì œëª©": title,
                    "B_ë‹¨ê³„": "ì˜ê²¬ì¡°íšŒ",
                    "C_ì‹œí–‰ë‚ ì§œ": final_exec_date,
                    "D_ì œì¶œë‚ ì§œ": submit_deadline_from_html if submit_deadline_from_html else final_submit_deadline,
                    "E_ì˜ˆì •ì¼": "",
                    "F_ë°˜ì˜ì¼ì": "",
                    "G_ì›ë£Œì„±ë¶„ëª…": ingredient_name,
                    "H_ê´€ë ¨ URL": record_url, # ì¶”ê°€ëœ ì»¬ëŸ¼
                    "I_ê´€ë ¨ PDF": record_pdf_path # ì¶”ê°€ëœ ì»¬ëŸ¼
                }

            elif status == "ì‚¬ì „ì˜ˆê³ ":
                record = {
                    "A_ì œëª©": title,
                    "B_ë‹¨ê³„": "ì‚¬ì „ì˜ˆê³ ",
                    "C_ì‹œí–‰ë‚ ì§œ": "",
                    "D_ì œì¶œë‚ ì§œ": "",
                    "E_ì˜ˆì •ì¼": plan_date_from_html if plan_date_from_html else final_plan_date,
                    "F_ë°˜ì˜ì¼ì": "",
                    "G_ì›ë£Œì„±ë¶„ëª…": ingredient_name,
                    "H_ê´€ë ¨ URL": record_url, # ì¶”ê°€ëœ ì»¬ëŸ¼
                    "I_ê´€ë ¨ PDF": record_pdf_path # ì¶”ê°€ëœ ì»¬ëŸ¼
                }

            elif status == "ë³€ê²½ëª…ë ¹":
                record = {
                    "A_ì œëª©": title,
                    "B_ë‹¨ê³„": "ë³€ê²½ëª…ë ¹",
                    "C_ì‹œí–‰ë‚ ì§œ": final_exec_date,
                    "D_ì œì¶œë‚ ì§œ": "",
                    "E_ì˜ˆì •ì¼": "",
                    "F_ë°˜ì˜ì¼ì": reflect_date_from_html if reflect_date_from_html else final_reflect_date,
                    "G_ì›ë£Œì„±ë¶„ëª…": ingredient_name,
                    "H_ê´€ë ¨ URL": record_url, # ì¶”ê°€ëœ ì»¬ëŸ¼
                    "I_ê´€ë ¨ PDF": record_pdf_path # ì¶”ê°€ëœ ì»¬ëŸ¼
                }

            records.append(record)
            print(f"    ğŸ“ ë ˆì½”ë“œ ì¶”ê°€ë¨")

            if not any([record.get("C_ì‹œí–‰ë‚ ì§œ"), record.get("D_ì œì¶œë‚ ì§œ"), record.get("E_ì˜ˆì •ì¼"), record.get("F_ë°˜ì˜ì¼ì"), record.get("G_ì›ë£Œì„±ë¶„ëª…")]):
                print(f"    âš ï¸  ê²½ê³ : ì´ í•­ëª© [{title}]ì—ì„œ í•„ìš”í•œ ëª¨ë“  ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨!")
                if current_item_processed_pdf_path: # ë‹¤ìš´ë¡œë“œëœ PDF íŒŒì¼ì´ ìˆë‹¤ë©´
                    print(f"    ğŸ” ì²˜ë¦¬ëœ PDF íŒŒì¼: {current_item_processed_pdf_path}")
                else:
                    print(f"    ğŸ” ì´ í•­ëª©ì— PDF ì²¨ë¶€íŒŒì¼ì´ ì—†ê±°ë‚˜ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")


        except TimeoutException:
            print(f"    âš ï¸  ì²¨ë¶€íŒŒì¼ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ ë˜ëŠ” ìƒì„¸ í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
        except Exception as detail_error:
            print(f"    âš ï¸  ìƒì„¸ í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {detail_error}")
        finally:
            driver.close()
            driver.switch_to.window(driver.window_handles[0])
            time.sleep(0.5)

    except Exception as e:
        print(f"[{idx}] âš ï¸  ì˜¤ë¥˜ ë°œìƒ: {e}")
        if len(driver.window_handles) > 1:
            driver.close()
            driver.switch_to.window(driver.window_handles[0])

def main():
    driver = webdriver.Chrome(options=options)
    records = []
    downloaded_files = set() # ì „ì²´ ì„¸ì…˜ì—ì„œ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ëª… ì¶”ì 
    max_items = 50 # ê¸°ë³¸ê°’ìœ¼ë¡œ ë‹¤ì‹œ ì„¤ì • (í•„ìš”í•˜ë©´ 10ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ë””ë²„ê¹…)

    try:
        print(f"ğŸš€ í¬ë¡¤ë§ ì‹œì‘... (ìµœê·¼ {max_items}ê±´ë§Œ ì²˜ë¦¬)")
       
        driver.get(BASE_URL)
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "table tbody tr"))
        )
       
        total_pages, total_items = get_total_pages(driver)
        print(f"ğŸ“Š í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ í˜„í™©:")
        print(f"   - ì´ í˜ì´ì§€: {total_pages}í˜ì´ì§€")
        print(f"   - ì´ í•­ëª©: {total_items}ê±´")
        print(f"   - ì²˜ë¦¬ ì˜ˆì •: ìµœì‹  {min(max_items, total_items)}ê±´")
       
        for page_num in range(1, total_pages + 1):
            if len(records) >= max_items:
                print(f"âœ… ëª©í‘œ {max_items}ê±´ ë„ë‹¬ë¡œ ì²˜ë¦¬ ì™„ë£Œ")
                break
               
            print(f"\nğŸ“„ === í˜ì´ì§€ {page_num}/{total_pages} ì²˜ë¦¬ ì¤‘ ===")
            print(f"í˜„ì¬ ì²˜ë¦¬ëœ ê±´ìˆ˜: {len(records)}/{max_items}")
           
            if not navigate_to_page(driver, page_num):
                continue
           
            rows = driver.find_elements(By.CSS_SELECTOR, "table tbody tr")
           
            for idx, row in enumerate(rows, start=(page_num-1)*10 + 1):
                if len(records) >= max_items:
                    print(f"âœ… ëª©í‘œ {max_items}ê±´ ë„ë‹¬ë¡œ í˜ì´ì§€ ë‚´ ì²˜ë¦¬ ì¤‘ë‹¨")
                    break
                   
                process_single_item(driver, row, idx, downloaded_files, records)
            
            print(f"í˜ì´ì§€ {page_num} ì™„ë£Œ - (ëˆ„ì : {len(records)}ê°œ)") 
           
            if len(records) >= max_items:
                break

    except Exception as e:
        print(f"âŒ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜: {e}")
    finally:
        driver.quit()

    print(f"\nğŸ“Š ìˆ˜ì§‘ ì™„ë£Œ!")
    print(f"ëª©í‘œ: {max_items}ê±´")
    print(f"ì‹¤ì œ ìˆ˜ì§‘ëœ ë ˆì½”ë“œ: {len(records)}ê°œ")
    print(f"ë‹¤ìš´ë¡œë“œëœ íŒŒì¼: {len(downloaded_files)}ê°œ")
   
    if records:
        df = pd.DataFrame(records).drop_duplicates()
       
        output_path = os.path.join(EXCEL_SAVE_DIR, f"ë³€ê²½ëª…ë ¹_ì˜ê²¬ì¡°íšŒ_ìš”ì•½_ìµœê·¼{len(df)}ê±´.xlsx")
       
        # --- ë³€ê²½ ì‹œì‘: xlsxwriter ì—”ì§„ ë° í•˜ì´í¼ë§í¬ í¬ë§· ì‚¬ìš© ---
        with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:
            workbook = writer.book
            hyperlink_format = workbook.add_format({'font_color': 'blue', 'underline': 1})

            # ì˜ê²¬ì¡°íšŒ ì‹œíŠ¸
            opinion_df = df[df['B_ë‹¨ê³„'] == 'ì˜ê²¬ì¡°íšŒ']
            if not opinion_df.empty:
                opinion_final = opinion_df[['A_ì œëª©', 'B_ë‹¨ê³„', 'C_ì‹œí–‰ë‚ ì§œ', 'D_ì œì¶œë‚ ì§œ', 'G_ì›ë£Œì„±ë¶„ëª…', 'H_ê´€ë ¨ URL', 'I_ê´€ë ¨ PDF']].copy()
                opinion_final.columns = ['ì œëª©', 'ë‹¨ê³„', 'ì‹œí–‰ë‚ ì§œ', 'ì œì¶œë‚ ì§œ', 'ì›ë£Œ/ì„±ë¶„ëª…(ì˜ë¬¸)', 'ê´€ë ¨ URL', 'ê´€ë ¨ PDF']
                opinion_final.to_excel(writer, sheet_name='ì˜ê²¬ì¡°íšŒ', index=False)
                worksheet = writer.sheets['ì˜ê²¬ì¡°íšŒ']
                
                # 'ê´€ë ¨ URL' ì»¬ëŸ¼ì— í•˜ì´í¼ë§í¬ ì ìš©
                for row_num, url in enumerate(opinion_final['ê´€ë ¨ URL'], start=1): # í—¤ë” ì œì™¸í•˜ê³  1ë¶€í„° ì‹œì‘
                    if url:
                        worksheet.write_url(row_num, opinion_final.columns.get_loc('ê´€ë ¨ URL'), url, hyperlink_format, url)
                
                # 'ê´€ë ¨ PDF' ì»¬ëŸ¼ì— í•˜ì´í¼ë§í¬ ì ìš© (ìƒëŒ€ ê²½ë¡œë¡œ ë³€í™˜)
                for row_num, pdf_path in enumerate(opinion_final['ê´€ë ¨ PDF'], start=1):
                    if pdf_path and os.path.exists(pdf_path):
                        relative_pdf_path = os.path.relpath(pdf_path, os.path.dirname(output_path))
                        worksheet.write_url(row_num, opinion_final.columns.get_loc('ê´€ë ¨ PDF'), relative_pdf_path, hyperlink_format, os.path.basename(pdf_path))
            
            # ì‚¬ì „ì˜ˆê³  ì‹œíŠ¸
            preview_df = df[df['B_ë‹¨ê³„'] == 'ì‚¬ì „ì˜ˆê³ ']
            if not preview_df.empty:
                preview_final = preview_df[['A_ì œëª©', 'B_ë‹¨ê³„', 'E_ì˜ˆì •ì¼', 'G_ì›ë£Œì„±ë¶„ëª…', 'H_ê´€ë ¨ URL', 'I_ê´€ë ¨ PDF']].copy()
                preview_final.columns = ['ì œëª©', 'ë‹¨ê³„', 'ì˜ˆì •ì¼', 'ì›ë£Œ/ì„±ë¶„ëª…(ì˜ë¬¸)', 'ê´€ë ¨ URL', 'ê´€ë ¨ PDF']
                preview_final.to_excel(writer, sheet_name='ì‚¬ì „ì˜ˆê³ ', index=False)
                worksheet = writer.sheets['ì‚¬ì „ì˜ˆê³ ']

                # 'ê´€ë ¨ URL' ì»¬ëŸ¼ì— í•˜ì´í¼ë§í¬ ì ìš©
                for row_num, url in enumerate(preview_final['ê´€ë ¨ URL'], start=1):
                    if url:
                        worksheet.write_url(row_num, preview_final.columns.get_loc('ê´€ë ¨ URL'), url, hyperlink_format, url)
                
                # 'ê´€ë ¨ PDF' ì»¬ëŸ¼ì— í•˜ì´í¼ë§í¬ ì ìš© (ìƒëŒ€ ê²½ë¡œë¡œ ë³€í™˜)
                for row_num, pdf_path in enumerate(preview_final['ê´€ë ¨ PDF'], start=1):
                    if pdf_path and os.path.exists(pdf_path):
                        relative_pdf_path = os.path.relpath(pdf_path, os.path.dirname(output_path))
                        worksheet.write_url(row_num, preview_final.columns.get_loc('ê´€ë ¨ PDF'), relative_pdf_path, hyperlink_format, os.path.basename(pdf_path))

            # ë³€ê²½ëª…ë ¹ ì‹œíŠ¸
            command_df = df[df['B_ë‹¨ê³„'] == 'ë³€ê²½ëª…ë ¹']
            if not command_df.empty:
                command_final = command_df[['A_ì œëª©', 'B_ë‹¨ê³„', 'C_ì‹œí–‰ë‚ ì§œ', 'F_ë°˜ì˜ì¼ì', 'G_ì›ë£Œì„±ë¶„ëª…', 'H_ê´€ë ¨ URL', 'I_ê´€ë ¨ PDF']].copy()
                command_final.columns = ['ì œëª©', 'ë‹¨ê³„', 'ì‹œí–‰ë‚ ì§œ', 'ë°˜ì˜ì¼ì', 'ì›ë£Œ/ì„±ë¶„ëª…(ì˜ë¬¸)', 'ê´€ë ¨ URL', 'ê´€ë ¨ PDF']
                command_final.to_excel(writer, sheet_name='ë³€ê²½ëª…ë ¹', index=False)
                worksheet = writer.sheets['ë³€ê²½ëª…ë ¹']

                # 'ê´€ë ¨ URL' ì»¬ëŸ¼ì— í•˜ì´í¼ë§í¬ ì ìš©
                for row_num, url in enumerate(command_final['ê´€ë ¨ URL'], start=1):
                    if url:
                        worksheet.write_url(row_num, command_final.columns.get_loc('ê´€ë ¨ URL'), url, hyperlink_format, url)
                
                # 'ê´€ë ¨ PDF' ì»¬ëŸ¼ì— í•˜ì´í¼ë§í¬ ì ìš© (ìƒëŒ€ ê²½ë¡œë¡œ ë³€í™˜)
                for row_num, pdf_path in enumerate(command_final['ê´€ë ¨ PDF'], start=1):
                    if pdf_path and os.path.exists(pdf_path):
                        relative_pdf_path = os.path.relpath(pdf_path, os.path.dirname(output_path))
                        worksheet.write_url(row_num, command_final.columns.get_loc('ê´€ë ¨ PDF'), relative_pdf_path, hyperlink_format, os.path.basename(pdf_path))
        # --- ë³€ê²½ ì¢…ë£Œ ---
       
        print(f"âœ… ì—‘ì…€ íŒŒì¼ ì €ì¥ ì™„ë£Œ!")
        print(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {output_path}")
        print(f"ğŸ“‹ ìµœì¢… ë ˆì½”ë“œ ìˆ˜: {len(df)}ê°œ")
       
        status_counts = df['B_ë‹¨ê³„'].value_counts()
        print(f"\nğŸ“ˆ ìƒíƒœë³„ í†µê³„:")
        for status_item, count_item in status_counts.items():
            print(f"  - {status_item}: {count_item}ê°œ")
       
        print(f"\nğŸ“‚ ì €ì¥ëœ íŒŒì¼ë“¤:")
        print(f"  ğŸ“Š ì—‘ì…€ íŒŒì¼: {output_path}")
        print(f"     - ì˜ê²¬ì¡°íšŒ ì‹œíŠ¸: {len(opinion_df) if 'opinion_df' in locals() else 0}ê±´")
        print(f"     - ì‚¬ì „ì˜ˆê³  ì‹œíŠ¸: {len(preview_df) if 'preview_df' in locals() else 0}ê±´")
        print(f"     - ë³€ê²½ëª…ë ¹ ì‹œíŠ¸: {len(command_df) if 'command_df' in locals() else 0}ê±´")
        print(f"  ğŸ“„ ë‹¤ìš´ë¡œë“œëœ PDF íŒŒì¼ë“¤: {DOWNLOAD_DIR}")
        print(f"     (ì´ {len(downloaded_files)}ê°œ PDF íŒŒì¼ì´ ë‹¤ìš´ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.)")
    else:
        print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
